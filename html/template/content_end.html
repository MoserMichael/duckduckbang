<link rel="stylesheet" href="github-markdown.css">
</head>
<body class="markdown-body">

<h1>Illustrated jq tutorial</h1>

<h2>The concept of pipes</h2>

Unix pipelines were invented in 1973 by <a href="https://en.wikipedia.org/wiki/Douglas_McIlroy">Douglas McIlroy</a> as a novel way of stringing together programs, where the output of one program is the input of the next one; It's a way of creating a new program out of combining basic building blocks, McIlroy describes it by analogy as <a href="https://web.archive.org/web/20040914025332/http://csdev.cas.upm.edu.ph/~pfalcone/compsci/unix/unix-history1.html">'screwing together data streams like a garden hose'</a>. This approach quickly became the UNIX philosophy of programming described by McIlroy as follows: 'Write programs that do one thing and do it well. Write programs to work together. Write programs that handle text streams, because that is a universal interface.' 

Lets say you want to know what are the most common words occurring within a text, the following pipeline will order the words of a text by frequency of usage:

<pre>
<a href="http://man7.org/linux/man-pages/man1/cat.1.html">cat</a> README.md  | <a href="http://man7.org/linux/man-pages/man1/tr.1.html">tr</a> " " "\n" | <a href="http://man7.org/linux/man-pages/man1/tr.1.html">tr</a>  -d '[:punct:]'  | <a href="http://man7.org/linux/man-pages/man1/sort.1.html">sort</a>   | <a href="http://man7.org/linux/man-pages/man1/uniq.1.html">uniq</a>  -c | sort -n -k 1 
</pre>

This example is a bit like functional programming: in each step of the pipeline the output depends only on the input received via the preceding pipe, each step acts on that text input only and produces its output without writing any files, that is without side effects.

<h3>Fast forward to the 21st century</h3>

Parsing of text streams is the Unix way of doing things and it has proven to be very versatile as is, however many application call for the exchange of structured data; There are more and more programs that use json as the format for exchanging structured data, examples are:

<ul>
    <li> kubernetes: the <a href="https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands">kubectl</a> and opeshift <a href="https://access.redhat.com/documentation/en-us/openshift_container_platform/4.2/html-single/cli_tools/index">oc</a> commands can produce its output in json format (option -o json)
    <li> the  <a href="https://github.com/Juniper/libxo">libxo</a> library is used with a variety of FreeBsd base utilities to produce json output; For example the <a href="https://www.freebsd.org/cgi/man.cgi?ps(1)">ps</a> command can produce json output with the --libxo option. Other converted base utilities of FreeBsd are listed <a href="https://wiki.freebsd.org/LibXo">here</a>
    <li> a project that produces json output for many common Linux base utilities is <a href="https://github.com/kellyjonbrazil/jc">jc</a>
</ul>

<h2>jq  - a tool for manipulating structured data</h2>

<a href="https://stedolan.github.io/jq/manual/">jq</a> is a very versatile tool for working with structured information in json format, the command syntax of jq is also structured by means of a processing pipeline, similar to that of a unix shell, again each processing step acts as a filter/modifier of the input received from the preceding stage. Again on might look at each of these stages as functions in a functional program.

This tutorial tries to explain jq in terms of example pipelines; each example comes with links that show you the intermediate results for each stage of the processing pipeline; i think this makes it easier to understand each of the building blocks involved. You can click either on any one of the commands to show the command and how it transforms the input json structure into the output json, each pipe symbol is also a link that will show you the information that flows through it.

The html for this tutorial is generated by <a href="https://github.com/MoserMichael/jq-illustrated/blob/master/scr.sh">this script</a> 


<h1>The tutorial</h1>



